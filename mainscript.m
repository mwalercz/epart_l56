% load data and remap labels[tvec tlab tstv tstl] = readSets(); tlab += 1;tstl += 1;% we have to implement properly activation and its derivative functionsx = -5:0.1:5;y = actf(x);plot(x, actf(x))% note that input to derivative function is not x (input value of the neuron) but the OUTPUT valueplot(x, actdf(y))% in implementation of the backprop I want to use very small training set[mu trmx] = prepTransform(tvec, 40);tvec40 = pcaTransform(tvec, mu, trmx);% just 3 first PCA components, two classes & 20 samples per classtrain = tvec40(tlab == 1, 1:3)(1:20, :);train = [train; tvec40(tlab == 2, 1:3)(1:20, :)];trlab = [ones(20,1); 2*ones(20,1)];size(train)% shuffling of data is important herereorder = randperm(40);train = train(reorder, :);trlab = trlab(reorder);% let's create the network[hidl outl] = crann(columns(train), 5, 2);% and start serious work ...[hhidl ooutl ter] = backprop(train, trlab, hidl, outl, 0.1);clres = anncls(train, hhidl, ooutl)confMx(trlab, clres)% After implementing backprop I'm ready to prepare my reference network% remove columns with zero std toRemain = std(tvec) != 0;tvec = tvec(:, toRemain);tstv = tstv(:, toRemain);% Overfitting noHiddenNeurons = 200;noEpochs = 20;learningRate = 0.005;[hln oln] = crann(columns(tvec), noHiddenNeurons, 10);totalError = zeros(1, noEpochs);trainError = zeros(1, noEpochs);validError = zeros(1, noEpochs);trReport = [];for epoch=1:noEpochs	tic();	[hln oln terr] = backprop(tvec, tlab, hln, oln, learningRate);  totalError(epoch) = terr;  	clsRes = anncls(tvec, hln, oln);	cfmx = confMx(tlab, clsRes);	errcf = compErrors(cfmx);  trainError(epoch) = errcf(2);    	epochTime = toc();	trReport = [trReport; epoch epochTime totalError(epoch) trainError(epoch)];	trReport(epoch, :)	fflush(stdout);end% Training set classification quality and confusion matrixclsRes = anncls(tvec, hln, oln);cfmx = confMx(tlab, clsRes)errcf = compErrors(cfmx)% Test set classification quality and confusion matrixclsRes = anncls(tstv, hln, oln);cfmx = confMx(tstl, clsRes)errcf = compErrors(cfmx)% No overfitting noHiddenNeurons = 200;noEpochs = 20;learningRate = 0.005;errorProportion = 1.5partitionCoeff = 0.8[hlnn olnn] = crann(columns(tvec), noHiddenNeurons, 10);totalError = zeros(1, noEpochs);trainError = zeros(1, noEpochs);validError = zeros(1, noEpochs);trReport = [];for epoch=1:noEpochs	tic();  % reporting how many digits we have for each train and validation labels in partition function  % move partition outside  [train_vec, train_lab, validation_vec, validation_lab] = partition(tvec, tlab, partitionCoeff); 	[hlnn olnn terr] = backprop(train_vec, train_lab, hlnn, olnn, learningRate);  totalError(epoch) = terr;  	clsRes = anncls(train_vec, hlnn, olnn);	cfmx = confMx(train_lab, clsRes);	errcf = compErrors(cfmx);  trainError(epoch) = errcf(2);    clsRes = anncls(validation_vec, hlnn, olnn);	cfmx = confMx(validation_lab, clsRes);	errcf = compErrors(cfmx);  validError(epoch) = errcf(2);  	epochTime = toc();	trReport = [trReport; epoch epochTime totalError(epoch) trainError(epoch) validError(epoch)];	trReport(epoch, :)	fflush(stdout);  if (validError(epoch) / trainError(epoch) >= errorProportion)    break;  endifend% Training set classification quality and confusion matrixclsRes = anncls(tvec, hlnn, olnn);cfmx = confMx(tlab, clsRes)errcf = compErrors(cfmx)% Test set classification quality and confusion matrixclsRes = anncls(tstv, hlnn, olnn);cfmx = confMx(tstl, clsRes)errcf = compErrors(cfmx)